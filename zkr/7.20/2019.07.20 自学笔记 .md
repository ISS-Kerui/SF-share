#2019.07.20 自学笔记

##一、聚类算法相关

###1、 Kmeans算法与改进

Kmeans 是机器学习算法中最经典的算法之一，其作用是对数据进行**聚类**。主要思想是:在给定K值和K个初始类簇中心点的情况下，把每个点(亦即数据记录)分到离其最近的类簇中心点所代表的类簇中，所有点分配完毕之后，根据一个类簇内的所有点重新计算该类簇的中心点(取平均值)，然后再迭代的进行分配点和更新类簇中心点的步骤，直至类簇中心点的变化很小，或者达到指定的迭代次数。这个算法中很关键的两个步骤就是如何**选取K值**和**初始化中心点**。它们在很大程度上影响着算法的效率。

#### 问题1：如何选取K值大小？

手肘法(核心指标为sum of the squared errors， 误差平方和)，其核心思想是：随着聚类数k的增大，样本划分会更加精细，每个簇的聚合程度会逐渐提高，那么误差平方和SSE自然会逐渐变小。并且，当k小于真实聚类数时，由于k的增大会大幅增加每个簇的聚合程度，故**SSE的下降幅度会很大**，而当k到达真实聚类数时，再增加k所得到的聚合程度**回报会迅速变小**，所以SSE的下降幅度会骤减，然后随着k值的继续增大而趋于平缓，也就是说SSE和k的关系图是一个手肘的形状，而这个**肘部对应的k值就是数据的真实聚类数**。当然，这也是该方法被称为手肘法的原因。
$$
SSE=\sum_i^k\sum|p-m_i|^2
$$

#### 问题2：如何初始化中心点？

一般的Kmeans算法直接采用随机的方式进行中心点的初始化，但这种方法不够高效。K-means++算法主要是对中心点初始化方法的改进。它的思想是尽量让聚类中心之间的距离变大。实现步骤为:

1. 从数据集中随机选取一个样本作为初始聚类中心；

2. 计算每个样本与当前已有聚类中心之间的最短距离，用D(x)表示；接着计算每个样本被选为下一个聚类中心的概率$D(x)^2/\sum_xD(x)^2$；

3. 接着，按照轮盘法选出下一个聚类中心；

4. 重复第二，三步直到选出K个聚类中心；

   

## 2、 具有噪声的基于密度的聚类方法(DBSCAN)

DBSCAN(Density-Based Spatial Clustering of Applications with Noise，具有噪声的基于密度的聚类方法)是一种很典型的密度聚类算法，和K-Means，BIRCH这些一般只适用于凸样本集的聚类相比，DBSCAN既可以适用于凸样本集，也可以适用于非凸样本集。下面我们就对DBSCAN算法的原理做一个总结。

和传统的K-Means算法相比，DBSCAN最大的不同就是**不需要输入类别数k**，当然它最大的优势是可以发现**任意形状的聚类簇**，而不是像K-Means，一般仅仅使用于凸的样本集聚类(球型范围)。同时它在聚类的同时还可以找出异常点，这点和BIRCH算法类似。**

那么我们什么时候需要用DBSCAN来聚类呢？一般来说，如果数据集是稠密的，并且数据集不是凸的，那么用DBSCAN会比K-Means聚类效果好很多。如果数据集不是稠密的，则不推荐用DBSCAN来聚类。

下面对DBSCAN算法的优缺点做一个总结。

DBSCAN的主要优点有：

　　　　1） 可以对**任意形状的稠密数据集进行聚类**，相对的，K-Means之类的聚类算法一般只适用于凸数据集。

　　　　2） 可以在聚类的同时**发现异常点**，对数据集中的异常点不敏感。

　　　　3） 聚类结果**没有偏倚**，相对的，K-Means之类的聚类算法初始值对聚类结果有很大影响。

DBSCAN的主要缺点有：

　　　　1）**如果样本集的密度不均匀**、聚类间距差相差很大时，聚类质量较差，这时用DBSCAN聚类一般不适合。

　　　　2） 如果样本集较大时，聚类收敛时间较长，此时可以对搜索最近邻时建立的KD树或者球树进行规模限制来改进。

　　　　3） 调参相对于传统的K-Means之类的聚类算法稍复杂，主要需要对**距离阈值ϵϵ**，**邻域样本数阈值MinPts**联合调参，不同的参数组合对最后的聚类效果有较大影响。

#### 1. DBSCAN算法的基本原理

其基本思想是：**对于一个簇中的每个对象，在其给定半径的领域中包含的对象不能少于某一给定的最小数目。**DBSCAN算法中有两个重要参数：ε表示定义密度时的邻域半径，M 表示定义核心点时的阈值。 大于M时，这个点为核心点；小于M时，且领域内有核心点，那么这个点为边界点；否则为噪声点。 然后将核心点，通过密度可达的规则进行聚类划分，密度可达的点形成一个聚类。

## 二、Python编程相关

#### 1. Numpy中的tile函数

tile就是将数组沿着各个方向进行一定倍数的复制。

比如 a = np.array([0,1,2]),    np.tile(a,(2,1))就是把a先沿x轴复制1倍，即没有复制，仍然是 [0,1,2]。 再把结果沿y方向复制2倍，即最终得到

 `array([[0,1,2],`

 `          [0,1,2]])`

#### 2. zip

**zip()** 函数用于将可迭代的对象(字典、列表等)作为参数，将对象中对应的元素（相同位置上的元素）打包成一个个元组，然后返回由这些元组组成的列表。注：如果两个对象长度不等也可以zip，只是会舍弃掉长度较长的部分。



