#2019.07.13-14 自学笔记

##一、大数据相关

###1、 大规模数据在有限内存上如何排序

分情况： ①可以一次读入内存 ②不可一次读入内存

所谓是否能一次读入内存，是指去重后的数据量。

对于情况①，如果去重后数据可以放入内存，我们可以为数据建立字典，比如通过map，hashmap，trie，

然后直接进行统计。

对于情况②，如果数据无法一次放入内存，我们可以考虑分治策略，它是一种对常见复杂问题的一种万能解法。虽然很多情节下，分治策略的解法都不是最优解，但是其通用性很强。

最常用的分治策略是 hash+堆排：

例如从1亿个整数中找出100个最大的数

步骤如下：

1、先对这批海量数据预处理，在O(N)的时间内用Hash表进行拆分映射。

2、将需要排序的数据切分为多个样本数大致相等的区间，例如：1-100，101-300… 这里要考虑IO次数和硬件资源问题，例如可将小数据文件数设定为1G（要预留内存给执行时的程序使用） 

3、读取每个小文件的前100个数字，建立最大值堆。（这里采用堆排序将空间复杂度讲得很低，要排序1亿个数，但一次性只需读取100个数字，或者设置其他基数，不需要1次性读完所有数据，降低对内存要求） 
4、依次读取余下的数，与最大值堆作比较，维持最大值堆。可以每次读取的数量为一个磁盘页面，将每个页面的数据依次进堆比较，这样节省IO时间。 
5、将堆进行排序，即可得到100个有序最大值。

6、最后对各个数据区间内的排序结果文件进行处理，最终每个区间得到一个排序结果的文件，将各个区间的排序结果合并。

可以很明显的看出，这个方法时间复杂度为NlogK。 借助堆结构，我们可以在log量级的时间内查找和调整/移动。因此，维护一个K(该题目中是100)大小的小根堆，然后遍历100万的Query，分别和根元素进行对比所以，我们最终的时间复杂度是：O(N) + N*O(logK)。

当然还有更好的方法，就是可以采用分布式计算，基本上就是**map-reduce**过程，首先可以根据数据值或者把数据hash(md5)后的值，将数据按照范围划分到不同的机子，最好可以让数据划分后可以一次读入内存，这样不同的机子负责处理各种的数值范围，实际上就是map。得到结果后，各个机子只需拿出各自的出现次数最多的前N个数据，然后汇总，选出所有的数据中出现次数最多的前N个数据，这实际上就是reduce过程。

实际上可能想直接将数据均分到不同的机子上进行处理，这样是无法得到正确的解的。因为一个数据可能被均分到不同的机子上，而另一个则可能完全聚集到一个机子上，同时还可能存在具有相同数目的数据。比如我们要找出现次数最多的前100个，我们将1000万的数据分布到10台机器上，找到每台出现次数最多的前100个，归并之后这样不能保证找到真正的第100个，因为比如出现次数最多的第100个可能有1万个，但是它被分到了10台机子，这样在每台上只有1千个，假设这些机子排名在1000个之前的那些都是单独分布在一台机子上的，比如有1001个，这样本来具有1万个的这个就会被淘汰，即使我们让每台机子选出出现次数最多的1000个再归并，仍然会出错，因为可能存在大量个数为1001个的发生聚集。**因此不能将数据随便均分到不同机子上，而是要根据hash后的值将它们映射到不同的机子上处理，让不同的机器处理一个数值范围。**

### 2、Spark与hadoop的区别？

Apache Spark的高性能一定程度上取决于它采用的**<u>异步并发</u>**模型（这里指[server](http://cpro.baidu.com/cpro/ui/uijs.php?rs=1&u=http%3A%2F%2Fwww.aboutyun.com%2Fthread-7233-1-1.html&p=baidu&c=news&n=10&t=tpclicked3_hc&q=92051019_cpr&k=server&k0=%C4%A3%D0%CD&kdi0=8&k1=spark&kdi1=8&k2=%B1%E0%B3%CC&kdi2=1&k3=server&kdi3=8&k4=%D2%FD%C7%E6&kdi4=8&sid=dd6b65e18133b08a&ch=0&tu=u1692056&jk=33d570781b48de2d&cf=29&fv=14&stid=9&urlid=0&luki=4&seller_id=1&di=128)/driver 端采用的模型），这与Hadoop 2.0（包括YARN和MapReduce）是一致的。Hadoop 2.0自己实现了类似<u>**Actor**</u>的异步并发模型，实现方式是epoll+状态机，而Apache Spark则直接采用了开源软件Akka，该软件实现了Actor模型，性能非常高。尽管二者在server端采用了一致的并发模型，但在任务级别（特指 Spark任务和MapReduce任务）上却采用了不同的并行机制：**Hadoop MapReduce采用了多进程模型，而Spark采用了多线程模型。**

- ##### 异步并发

  同步和异步关注的是结果消息的通信机制 
  - 同步:同步的意思就是调用方需要主动等待结果的返回。
  - 异步:异步的意思就是不需要主动等待结果的返回，而是通过其他手段比如，状态通知，回调函数等。

  阻塞和非阻塞主要关注的是等待结果返回调用方的状态

  - 阻塞: 是指结果返回之前，当前线程被挂起，不做任何事。
  - 非阻塞: 是指结果在返回之前，线程可以做一些其他事，不会被挂起。

- Actor模型

  Scala中的Actor能够实现并行编程的强大功能，它是基于事件模型的并发机制，Scala是运用消息的发送、接收来实现高并发的。(比spark的方法快)

  Actor可以看作是一个个独立的实体，他们之间是毫无关联的。但是，他们可以通过消息来通信。一个Actor收到其他Actor的信息后，它可以根据需要作出各种相应。消息的类型可以是任意的，消息的内容也可以是任意的。actor之间不共享任何数据，只依赖消息的传递。

- 多进程模型与多线程模型

  多进程模型便于细粒度控制每个任务占用的资源，但会消耗较多的启动时间，不适合运行低延迟类型的作业，这是MapReduce广为诟病的原因之一。而多线程模型则相反，该模型使得Spark很适合运行低延迟类型的作业。总之，Spark同节点上的任务以多线程的方式运行在一个JVM进程中，可带来以下好处：

  1）任务启动速度快，与之相反的是MapReduce Task进程的慢启动速度，通常需要1s左右；

  2）同节点上所有任务运行在一个进程中，有利于共享内存。这非常适合内存密集型任务，尤其对于那些需要加载大量词典的应用程序，可大大节省内存。

  3） 同节点上所有任务可运行在一个JVM进程(Executor)中，且Executor所占资源可连续被多批任务使用，不会在运行部分任务后释放掉，这避免了每个任务重复申请资源带来的时间开销，对于任务数目非常多的应用，可大大降低运行时间。与之对比的是MapReduce中的Task：每个Task单独申请资源，用完后马上释放，不能被其他任务重用，尽管1.0支持JVM重用在一定程度上弥补了该问题，但2.0尚未支持该功能。

  **尽管Spark的多线程模型带来了很多好处，但同样存在不足，主要有：**

  由于同节点上所有任务运行在一个进程中，因此，会出现严重的资源争用，难以细粒度控制每个任务占用资源。与之相反的是MapReduce，它允许用户单独为Map Task和Reduce Task设置不同的资源（ 可单独为不同类型的Task设置不同的资源量，目前支持内存和CPU两种资源），进而细粒度控制任务占用资源量，有利于大作业的正常**平稳运行**（更稳定）。

  **总体上看**，Spark采用的是经典的scheduler/workers模式， 每个Spark应用程序运行的第一步是构建一个可重用的资源池，然后在这个资源池里运行所有的ShuffleMapTask和ReduceTask（注 意，尽管Spark编程方式十分灵活，不再局限于编写Mapper和Reducer，但是在Spark引擎内部只用两类Task便可表示出一个复杂的应用 程序，即ShuffleMapTask和ReduceTask），而MapReduce应用程序则不同，它不会构建一个可重用的资源池，而是让每个 Task动态申请资源，且运行完后马上释放资源。

## 二、机器学习相关

### 1、极大似然与EM算法

极大似然的本质就是知道样本和其分布类型去求解分布的参数。

极大似然估计，只是一种概率论在统计学的应用，它是参数估计的方法之一。说的是已知某个随机样本满足某种概率分布，但是其中具体的参数不清楚，参数估计就是通过若干次试验，观察其结果，利用结果推出参数的大概值。最大似然估计是建立在这样的思想上：已知某个参数能使这个样本出现的概率最大，我们当然不会再去选择其他小概率的样本，所以干脆就把这个参数作为估计的真实值。

**求最大似然函数估计值的一般步骤：**

（1）写出似然函数；

（2）对似然函数取对数，并整理；

（3）求导数，令导数为0，得到似然方程；

（4）解似然方程，得到的参数即为所求；

**而EM算法要比极大似然估计更复杂**，因为你无法确定抽取得到的每个样本是属于哪个分布的。所以我们除了要确定分布的参数，还要确定这个样本的类别是什么。只有我们知道了哪些样本属于同一个分布时，我们才能对这个分布的参数做出靠谱的预测。